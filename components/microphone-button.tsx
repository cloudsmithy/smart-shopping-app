"use client";

import { useState, useRef, useEffect } from "react";
import { createPortal } from "react-dom";
import { Mic } from "lucide-react";
import { createRealtimeSession } from "@/api/ai";
import type React from "react";

interface MicrophoneButtonProps {
  onNavigate: (screen: string) => void;
  onAudioRecorded?: (audioFile: File) => void;
  isProcessing?: boolean;
  onUserTranscription?: (text: string) => void;
  onAssistantResponse?: (text: string, audioUrl?: string) => void;
  initialContext?: {
    photoData?: {
      imageUrl: string;
      photoUrl: string;
      recognitionResult: string;
    };
    userMessages?: string[];
    systemMessages?: Array<{
      text: string;
      audioUrl?: string;
    }>;
  };
}

export default function MicrophoneButton({
  onNavigate,
  onAudioRecorded,
  isProcessing = false,
  onUserTranscription,
  onAssistantResponse,
  initialContext,
}: MicrophoneButtonProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [isConnecting, setIsConnecting] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [logging, setLogging] = useState<string[]>([]);

  // WebRTC refs
  const pcRef = useRef<RTCPeerConnection | null>(null);
  const dcRef = useRef<RTCDataChannel | null>(null);
  const audioRef = useRef<HTMLAudioElement>(null);
  const localStreamRef = useRef<MediaStream | null>(null);

  // ç”¨äºç´¯ç§¯å“åº”æ–‡æœ¬
  const currentResponseTextRef = useRef<string>("");

  const log = (msg: string) => {
    console.log(msg);
    setLogging(prev => [...prev, msg]);
  };

  // Cleanup function
  const cleanup = () => {
    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach(track => track.stop());
      localStreamRef.current = null;
    }
    
    if (dcRef.current) {
      dcRef.current.close();
      dcRef.current = null;
    }
    
    if (pcRef.current) {
      pcRef.current.close();
      pcRef.current = null;
    }
    
    if (audioRef.current) {
      audioRef.current.srcObject = null;
    }
    
    // é‡ç½®ç´¯ç§¯æ–‡æœ¬
    currentResponseTextRef.current = "";
    
    setIsRecording(false);
    setIsConnecting(false);
    setLogging([]);
  };

  useEffect(() => {
    return cleanup;
  }, []);

  const startRealtimeSession = async () => {
    try {
      setError(null);
      setIsConnecting(true);
      setLogging([]);
      
      log("ğŸš€ å¼€å§‹å»ºç«‹å®æ—¶è¯­éŸ³ä¼šè¯...");

      // â‘  ä»åç«¯è·å– ephemeral key
      const { session_id, ephemeral_key } = await createRealtimeSession();
      log(`ğŸ†— Session ${session_id} è·å–æˆåŠŸ`);

      // â‘¡ åˆå§‹åŒ– WebRTC
      const pc = new RTCPeerConnection();
      pcRef.current = pc;

      // æ”¶åˆ°æ¨¡å‹è¿”å›çš„éŸ³é¢‘ track
      pc.ontrack = (ev) => {
        log("ğŸµ æ”¶åˆ°éŸ³é¢‘æµ");
        if (audioRef.current && ev.streams[0]) {
          audioRef.current.srcObject = ev.streams[0];
          audioRef.current.play().catch(error => {
            log(`âŒ éŸ³é¢‘æ’­æ”¾å¤±è´¥: ${error}`);
          });
        }
      };

      // è¿æ¥çŠ¶æ€ç›‘å¬
      pc.onconnectionstatechange = () => {
        log(`ğŸ“¡ è¿æ¥çŠ¶æ€: ${pc.connectionState}`);
        if (pc.connectionState === 'failed' || pc.connectionState === 'disconnected') {
          setError("è¿æ¥å¤±è´¥ï¼Œè¯·é‡è¯•");
          cleanup();
        }
      };

      // å»ºç«‹æ•°æ®é€šé“
      const dc = pc.createDataChannel("realtime-channel");
      dcRef.current = dc;

      dc.onopen = () => {
        log("ğŸ“¡ æ•°æ®é€šé“å·²æ‰“å¼€");
        setIsConnecting(false);
        setIsRecording(true);
        
        // æ„å»ºç³»ç»ŸæŒ‡ä»¤ï¼ŒåŒ…å«å›¾ç‰‡è¯†åˆ«ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        let instructions = "ä½ æ˜¯ä¸€ä½è€å¿ƒã€ä¸“ä¸šçš„ä¸­æ–‡è´­ç‰©åŠ©ç†ã€‚è¯·ç”¨ç®€æ´ã€å‹å¥½çš„è¯­æ°”å›ç­”ç”¨æˆ·å…³äºå•†å“çš„é—®é¢˜ã€‚";
        
        if (initialContext?.photoData) {
          instructions += `\n\nå½“å‰ç”¨æˆ·å·²ä¸Šä¼ å•†å“å›¾ç‰‡ï¼Œè¯†åˆ«ç»“æœï¼š${initialContext.photoData.recognitionResult}ã€‚å›¾ç‰‡URL: ${initialContext.photoData.imageUrl}ã€‚è¯·ç»“åˆè¿™ä¸ªå•†å“ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚`;
        }
        
        // å‘é€ä¼šè¯é…ç½®
        const sessionUpdate = {
          type: "session.update",
          session: { 
            instructions: instructions,
            voice: "alloy",
            input_audio_format: "pcm16",
            output_audio_format: "pcm16",
            input_audio_transcription: {
              model: "whisper-1"
            },
            turn_detection: {
              type: "server_vad",
              threshold: 0.5,
              prefix_padding_ms: 300,
              silence_duration_ms: 500
            }
          }
        };
        dc.send(JSON.stringify(sessionUpdate));
        log("â¡ï¸ ä¼šè¯é…ç½®å·²å‘é€");
        
        // å¦‚æœæœ‰åˆå§‹ä¸Šä¸‹æ–‡ï¼Œå‘é€å¯¹è¯å†å²
        if (initialContext && (
          (initialContext.userMessages && initialContext.userMessages.length > 0) || 
          (initialContext.systemMessages && initialContext.systemMessages.length > 0)
        )) {
          log("ğŸ“š å¼€å§‹å‘é€å¯¹è¯å†å²");
          
          try {
            // åˆå¹¶ç”¨æˆ·æ¶ˆæ¯å’Œç³»ç»Ÿæ¶ˆæ¯ï¼ŒæŒ‰æ—¶é—´é¡ºåºæ’åˆ—
            const allMessages: Array<{type: 'user' | 'assistant', content: string}> = [];
            
            // å‡è®¾æ¶ˆæ¯æ˜¯æŒ‰é¡ºåºäº¤æ›¿å‡ºç°çš„ï¼Œå…ˆæ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼Œå†æ·»åŠ å¯¹åº”çš„ç³»ç»Ÿæ¶ˆæ¯
            const userMsgs = initialContext.userMessages || [];
            const systemMsgs = initialContext.systemMessages || [];
            const maxLength = Math.max(userMsgs.length, systemMsgs.length);
            
            for (let i = 0; i < maxLength; i++) {
              // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
              if (i < userMsgs.length && userMsgs[i]?.trim()) {
                allMessages.push({
                  type: 'user',
                  content: userMsgs[i].trim()
                });
              }
              
              // æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
              if (i < systemMsgs.length && systemMsgs[i]?.text?.trim()) {
                allMessages.push({
                  type: 'assistant',
                  content: systemMsgs[i].text.trim()
                });
              }
            }
            
            // å‘é€æ¯æ¡å†å²æ¶ˆæ¯
            allMessages.forEach((message, index) => {
              if (message.content && message.content.length > 0) {
                const conversationItem = {
                  type: "conversation.item.create",
                  item: {
                    type: "message",
                    role: message.type,
                    content: [{
                      type: "text",
                      text: message.content
                    }]
                  }
                };
                
                dc.send(JSON.stringify(conversationItem));
                log(`ğŸ“ å‘é€å†å²æ¶ˆæ¯ ${index + 1}/${allMessages.length}: ${message.type} - ${message.content.substring(0, 50)}...`);
              }
            });
            
            log(`âœ… å¯¹è¯å†å²å‘é€å®Œæˆï¼Œå…± ${allMessages.length} æ¡æ¶ˆæ¯`);
          } catch (error) {
            log(`âŒ å‘é€å¯¹è¯å†å²æ—¶å‡ºé”™: ${error}`);
          }
        } else {
          log("ğŸ“š æ— å†å²å¯¹è¯éœ€è¦å‘é€");
        }
      };

      dc.onmessage = (e) => {
        try {
          const data = JSON.parse(e.data);
          log(`â¬…ï¸ ${data.type}`);
          
          // å¤„ç†ä¸åŒç±»å‹çš„æ¶ˆæ¯
          if (data.type === 'input_audio_buffer.speech_stopped') {
            log("ğŸ¤ ç”¨æˆ·åœæ­¢è¯´è¯");
          } else if (data.type === 'conversation.item.input_audio_transcription.completed') {
            // ç”¨æˆ·è¯­éŸ³è½¬å½•å®Œæˆ
            if (data.transcript && onUserTranscription) {
              log(`ğŸ‘¤ ç”¨æˆ·è¯´: ${data.transcript}`);
              onUserTranscription(data.transcript);
            }
          } else if (data.type === 'response.audio_transcript.delta') {
            // AIå“åº”æ–‡æœ¬å¢é‡æ›´æ–°
            if (data.delta) {
              currentResponseTextRef.current += data.delta;
              log(`ğŸ¤– AIå›å¤å¢é‡: ${data.delta}`);
            }
          } else if (data.type === 'response.audio_transcript.done') {
            // AIå“åº”æ–‡æœ¬å®Œæˆ
            const fullText = currentResponseTextRef.current;
            if (fullText && onAssistantResponse) {
              log(`ğŸ¤– AIå®Œæ•´å›å¤: ${fullText}`);
              onAssistantResponse(fullText);
            }
            // é‡ç½®ç´¯ç§¯æ–‡æœ¬
            currentResponseTextRef.current = "";
          } else if (data.type === 'response.audio.delta' && data.delta) {
            // å¤„ç†éŸ³é¢‘æ•°æ® - è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦è¿›ä¸€æ­¥å¤„ç†
            log("ğŸµ æ”¶åˆ°éŸ³é¢‘å¢é‡");
          } else if (data.type === 'error') {
            log(`âŒ é”™è¯¯: ${data.error?.message || 'æœªçŸ¥é”™è¯¯'}`);
            setError(data.error?.message || 'å‘ç”ŸæœªçŸ¥é”™è¯¯');
          }
        } catch (err) {
          log(`â¬…ï¸ ${e.data}`);
        }
      };

      dc.onerror = (error) => {
        log(`âŒ æ•°æ®é€šé“é”™è¯¯: ${error}`);
        setError("æ•°æ®é€šé“è¿æ¥å¤±è´¥");
      };

      // â‘¢ é‡‡é›†éº¦å…‹é£
      const localStream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 24000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      });
      localStreamRef.current = localStream;
      localStream.getAudioTracks().forEach(track => pc.addTrack(track, localStream));
      log("ğŸ¤ éº¦å…‹é£å·²è¿æ¥");

      // â‘£ SDP æ¡æ‰‹
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      const webrtcURL = `https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2025-06-03`;

      const answerSDP = await fetch(webrtcURL, {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${ephemeral_key}`,
          "Content-Type": "application/sdp"
        },
        body: offer.sdp
      }).then(r => r.text());

      await pc.setRemoteDescription({ type: "answer", sdp: answerSDP });
      log("âœ… WebRTC è¿æ¥å·²å»ºç«‹");

    } catch (err) {
      console.error("å¯åŠ¨å®æ—¶ä¼šè¯å¤±è´¥:", err);
      setError(err instanceof Error ? err.message : "æ— æ³•å»ºç«‹è¯­éŸ³è¿æ¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œå’Œéº¦å…‹é£æƒé™");
      setIsConnecting(false);
      cleanup();
    }
  };

  const stopRealtimeSession = () => {
    log("ğŸ”š æ­£åœ¨å…³é—­ä¼šè¯...");
    cleanup();
  };

  const handleClick = () => {
    if (isRecording) {
      stopRealtimeSession();
    } else if (!isConnecting) {
      startRealtimeSession();
    }
  };

  return (
    <>
      {/* å…¨å±é®ç½©å’Œå½•éŸ³æç¤º */}
      {(isRecording || isConnecting) && typeof window !== 'undefined' && createPortal(
        <div 
          className="fixed inset-0 bg-black/60 backdrop-blur-sm z-[9999] flex items-center justify-center"
          style={{ pointerEvents: 'auto' }}
        >
          <div className="flex flex-col items-center space-y-8 max-w-md mx-4">
            {/* å½•éŸ³åŠ¨ç”»åœ†åœˆ */}
            <div className="relative">
              <div className="w-32 h-32 bg-white/10 rounded-full flex items-center justify-center animate-pulse">
                <div className="w-24 h-24 bg-white/20 rounded-full flex items-center justify-center">
                  <div className="w-16 h-16 bg-gradient-to-br from-blue-500 to-indigo-600 rounded-full flex items-center justify-center shadow-2xl">
                    <Mic className="w-8 h-8 text-white" />
                  </div>
                </div>
              </div>
              {/* å½•éŸ³è„‰å†²æ•ˆæœ */}
              {isRecording && (
                <div className="absolute inset-0 flex items-center justify-center">
                  <div className="w-32 h-32 bg-blue-500/20 rounded-full animate-ping" />
                </div>
              )}
            </div>
            
            {/* æç¤ºæ–‡å­— */}
            <div className="text-center space-y-4">
              <div className="space-y-2">
                <p className="text-white text-xl font-medium">
                  {isConnecting ? "æ­£åœ¨è¿æ¥..." : "å®æ—¶è¯­éŸ³å¯¹è¯ä¸­..."}
                </p>
                {isConnecting && (
                  <p className="text-white/70 text-sm">è¯·ç¨å€™ï¼Œæ­£åœ¨å»ºç«‹è¿æ¥</p>
                )}
              </div>
              
              {/* æ—¥å¿—æ˜¾ç¤ºï¼ˆå¼€å‘æ—¶å¯è§ï¼‰ */}
              {process.env.NODE_ENV === 'development' && logging.length > 0 && (
                <div className="bg-black/20 rounded-lg p-3 max-h-32 overflow-y-auto">
                  <pre className="text-xs text-white/80 text-left">
                    {logging.slice(-5).join('\n')}
                  </pre>
                </div>
              )}
              
              {/* å–æ¶ˆæŒ‰é’® */}
              {!isConnecting && (
                <div className="flex justify-center">
                  <button
                    onClick={stopRealtimeSession}
                    className="w-12 h-12 bg-red-500/20 hover:bg-red-500/30 backdrop-blur-sm rounded-full flex items-center justify-center transition-all duration-200 border border-red-500/30"
                    style={{ pointerEvents: 'auto' }}
                    aria-label="ç»“æŸå¯¹è¯"
                  >
                    <svg 
                      className="w-6 h-6 text-white" 
                      fill="none" 
                      stroke="currentColor" 
                      viewBox="0 0 24 24"
                    >
                      <path 
                        strokeLinecap="round" 
                        strokeLinejoin="round" 
                        strokeWidth={2} 
                        d="M6 18L18 6M6 6l12 12" 
                      />
                    </svg>
                  </button>
                </div>
              )}
            </div>
          </div>
        </div>,
        document.body
      )}

      {/* éšè—çš„éŸ³é¢‘å…ƒç´ ç”¨äºæ’­æ”¾AIå›å¤ */}
      <audio ref={audioRef} autoPlay style={{ display: 'none' }} />

      <div className="relative">
        {error && (
          <div 
            className="absolute -top-12 left-1/2 transform -translate-x-1/2 bg-red-500/90 backdrop-blur-sm rounded-xl whitespace-nowrap shadow-lg text-force-white"
            style={{
              backgroundColor: '#ef4444',
              color: '#ffffff',
              padding: '8px 16px',
              fontSize: '12px',
              zIndex: 60,
            }}
          >
            <span style={{color: '#ffffff'}}>{error}</span>
          </div>
        )}

        <button
          type="button"
          className={`w-16 h-16 bg-gradient-to-br from-blue-600 to-indigo-700 rounded-2xl flex items-center justify-center shadow-xl shadow-blue-500/30 transition-all duration-200 relative ${
            isRecording ? 'z-[9998]' : 'z-50'
          } ${
            isProcessing || isConnecting ? "opacity-50 cursor-not-allowed" : "hover:from-blue-700 hover:to-indigo-800 hover:shadow-2xl hover:shadow-blue-500/40"
          }`}
          style={{ backgroundColor: '#2563eb' }}
          onClick={isProcessing ? undefined : handleClick}
          disabled={isProcessing}
          aria-label={isRecording ? "ç»“æŸå¯¹è¯" : isConnecting ? "è¿æ¥ä¸­" : "å¼€å§‹è¯­éŸ³å¯¹è¯"}
        >
          <Mic
            className={`w-7 h-7 ${
              isRecording || isConnecting || isProcessing ? "animate-pulse" : ""
            }`}
            style={{color: '#ffffff'}}
          />
        </button>
      </div>
    </>
  );
}
